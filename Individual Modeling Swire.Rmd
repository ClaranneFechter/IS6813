---
title: "Individual Modeling Swire"
author: "Claranne Fechter"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
---

# Introduction

Swire Coca-Cola has begun the use of its new digital ordering platform, MyCoke360, and it has been running for a little over a year. Cart abandonment is something all businesses have to worry about, and Swire is no different. In this context, cart abandonment is described as when a customer adds items to their cart, but does not make a purchase before their next order date. This abandonment can lead to a loss in revenue. Swire has tasked us with identifying what tends to influence a customer to abandon their carts. The purpose of this notebook is to test different models that can help us understand which variables influence a cart that is abandoned and what leads customers to leaving their cart. We want to investigate what variables could influence customers and what actions they take within their carts.

# Libraries and Loads
```{r}
library(tidyverse)
library(dplyr)
library(skimr)
library(ggplot2)
library(janitor)
library(lubridate)
library(scales)
library(caret)

# Load files
customer <- read_csv("customer.csv")
cutoff_times <- read_csv("cutoff_times.csv")
google_analytics <- read_csv("google_analytics.csv")
material <- read_csv("material.csv")
operating_hours <- read_csv("operating_hours.csv")
orders <- read_csv("orders.csv")
sales <- read_csv("sales.csv")
visit_plan <- read_csv("visit_plan.csv")
```

# Cleaning and Data Preparation

In this notebook, we used the cleaning from our EDA, however, we have added a few things. We were able to create the order windows and the target variable, which was the most complex step. We first joined the customer and cutoff tables to understand each customers policy and get each start and end date of the window. With these defined windows, we were then able to classify if the cart was abandoned or a purchase was made. We used the GA table where customers clicked add to cart but there was no purchase from the orders table, to define the cart as abandoned. After doing these crucial steps, we joined the events to the window that they belonged in to be able to see customer behavior. Lastly, we removed NAs and sampled the dataset by randomly selecting 50% of the unique customers. We chose to sample this many so that modeling would run smoother and hopefully have quicker run times.

# GA Cleaning

```{r}
# make column names lowercase, get rid of any spaces
ga_clean <- google_analytics |>
  clean_names()

ga_clean <- ga_clean |>
  mutate(
    # make character columns character types
    customer_id = trimws(as.character(customer_id)),
    event_timestamp = as.character(event_timestamp),
    event_date = as.character(event_date),
    event_name = as.character(event_name),
    device_category = as.character(device_category),
    event_page_name = as.character(event_page_name),
    event_page_title = as.character(event_page_title),
    
    # get day from event date
    # get it from event timestamp if missing
    day = as.Date(event_date, format = "%m/%d/%Y"),
    day = ifelse(is.na(day), as.Date(substr(event_timestamp, 1, 10)), day),
    day = as.Date(day, origin = "1970-01-01"),  # make sure it's correct class
    
    # Normalize event name
    event_name_norm = tolower(trimws(event_name))
  )

#Add new column to group events into more comprehensible names to focus on what matters
ga_clean <- ga_clean |>
  mutate(event_grouped = case_when(
    
    event_name %in% c("AccountSelect_SwitchAccount_Clicked","AccountSelect_SwitchAccount_Completed",
                      "Close_SwitchAccount_Clicked","login","Login_Cancelled","Login_Clicked",
                      "Login_Home_Page_Displayed","logout","Logout_Profile_Clicked",
                      "SwitchAccountPopup_Dispayed") ~ "Account",
    
    event_name %in% c("Account_Pressed_Failed","Get_Account_Details_Failed",
                      "Get_Account_Easy_Order_Failed","Get_Delegated_Account_Failed",
                      "Is_Account_Blocked_For_Ordering_Failed","Logout_Profile_Failed",
                      "SSO_Token_Details_Failed",
                      "Get_User_Details_From_User_Id_Failed") ~ "Account_Failed",
    
    event_name %in% c("add_to_cart","CartPage_Displayed","CartProductQuantity_Cart_Changed",
                      "ContinueShopping_Cart_Clicked","export_cart_click",
                      "ProductAddtoCart_PDP_Clicked","ProductAddtoCart_PLP_Clicked",
                      "ProductCheckmark_Cart_Checked","ProductCheckmark_Cart_Unchecked",
                      "ProductSelected_Cart_Clicked","remove_from_cart","SelectAll_Cart_Checked",
                      "SelectAll_Cart_Unchecked","update_cart","UpdateCart_Cart_Clicked",
                      "UpdateCart_Cart_Retrieved","view_cart") ~ "Cart",
    
    event_name %in% c("CartProducts_Cart_Retrieve_Failed","Handle_Add_To_Cart_Failed",
                      "ProductAddtoCart_PLP_Failed","Update_Cart_Details_For_Payment_Failed",
                      "Update_Cart_Item_With_Price_Data_Failed","Update_Cart_With_Details_Failed",
                      "Update_Web_Cart_Failed","Error_Get_cart_data","Error_get_webcart_details",
                      "Get_Active_Cart_Items_Failed","Get_Cart_Count_Failed",
                      "Get_Product_Quantity_In_Cart_Failed") ~ "Cart_Failed",
    
    event_name %in% c("add_payment_info","add_shipping_info","begin_checkout",
                      "proceed_to_checkout","CheckoutPage_Displayed",
                      "CheckoutData_CheckoutPage_Retrieved") ~ "Checkout",
    
    event_name %in% c("OrderSuccessPage_Displayed","purchase") ~ "Purchase",
    
    event_name %in% c("On_Proceed_To_Checkout_Click_Failed","OrderSubmit_CheckoutPage_Failed",
                      "Process_Payment_Error","Payment_API_Failed","Error_Handle_Payment_Method",
                      "Get_Payment_Methods_Data_Failed","Get_Payment_Method_Failed",
                      "Get_SnapPay_Mapping_MetaData_Failed","CheckoutData_Retrieve_Failed",
                      "cancel_order") ~ "Checkout_Failed",
    
    event_name %in% c("Categories_PLP_Retrieved","filter_by","Images_PDP_Reteieved",
                      "ProductCount_PDP","ProductCount_PLP","ProductsList_PLP_Retrieved",
                      "select_item","select_promotion","sort_by","view_item","view_item_list",
                      "view_promotion","view_search_results",
                      "view_site_search") ~ "Item",
    
    event_name %in% c("Images_PDP_Reteieve_Failed","ProductsList_PLP_Retrieve_Failed",
                      "Get_Assortment_Product_List_Failed",
                      "Get_Filter_Options_Failed") ~ "Item_Failed",
    
    event_name %in% c("InvoiceList_InvoiceTab_Retrieved","InvoiceListFilter_InvoiceTab_Successfull",
                      "OrderTab_Displayed","pay_invoice_click",
                      "RecentPayedInvoice_InvoiceTab_Clicked","search_invoice",
                      "search_order_history") ~ "Orders_Invoices",
    
    event_name %in% c("Check_Prod_For_AML_And_Inventory_Failed","Get_Delivery_Dates_Api_Failed",
                      "Get_Invoice_Data_Failed","Get_Invoice_Details_Failed",
                      "Get_Oct_Invoice_Failed","Get_Order_History_Failed",
                      "Get_Order_History_Filter_Options_Failed","Get_Recent_Order_Data_Failed",
                      "InvoiceList_InvoiceTab_Retrieve_Failed","Create_Delivery_Quantity_Failed",
                      "Error_Delivery_Method",
                      "Delete_Order_History_Cache_Failed","refund") ~ "Orders_Invoices_Failed",
    
    event_name %in% c("BackClicked_CST","CloseTicket_EST_Clicked","CloseTicket_EST_Successful",
                      "create_ticket","SupportTab_Displayed","Ticked_CST_Clicked",
                      "Ticked_EST_Clicked","Ticket_CST_Displayed","Ticket_EST_Displayed",
                      "TicketList_CST_Retrieved","TicketList_EST_Retrieved",
                      "TicketListFilter_CST_Successfull","TicketListFilter_EST_Successfull",
                      "TicketSearch_CST_Clicked","TicketSearch_EST_Clicked") ~ "Tickets",
    
    event_name %in% c("Post_Create_ESTCST_Ticket_Failed","TicketList_CST_Retrieve_Failed",
                      "TicketList_EST_Retrieve_Failed") ~ "Tickets_Failed",
    
    event_name %in% c("application_launched","app_remove","app_update","BackClicked_PDP",
                      "button_click","Close_Profile_Clicked","homepage_register_now",
                      "nav_link_click","page_view","ProfilePopup_Displayed","screen_view",
                      "session_start","user_engagement","first_visit") ~ "Engagement",
    
    event_name %in% c("Get_Banner_Images_Dashboard_Count","Get_Banner_Images_Plp_Count",
                      "Get_Banner_Images_Time_Comparison",
                      "Maintenance_Flag_Successful","os_update") ~ "Other_Success",
    
    event_name %in% c("AML_Validation_Failed","Error_post_create_webcart",
                      "Error_Updating_Session_Delivery","Fetch_Menu_Access_Failed",
                      "Get_Banner_Images_Failed","Get_Bottler_Meta_Data_Failed",
                      "Get_Web_Store_Failed","Handle_Auth_Success_Failed",
                      "handle_save_azure_key_failed","Get_Is_Dom_Enabled_Failed",
                      "Get_Decision_Tree_Data_Failed") ~ "Other_Failed",
    
    TRUE ~ "Other"))
```

# Orders Cleaning

```{r}
# make column names lowercase, get rid of any spaces
orders_clean <- orders |>
  clean_names()

# make character columns characters, created dates as dates
# create purchased columns, if order quantity is 0 then no purchase
orders_clean <- orders_clean |>
  mutate(customer_id = trimws(as.character(customer_id)),
         plant_id = as.factor(plant_id),
         created_date_est = as.Date(created_date_est),
         created_date_utc = lubridate::ymd_hms(created_date_utc, tz = "UTC"),
         order_purchased = if_else(order_quantity == 0, "No Purchase", "Purchased", missing = "No Purchase"))
```

# Visitplan Cleaning

```{r}
# make column names lowercase, get rid of any spaces
visits_clean <- visit_plan |>
  clean_names()

# don't need any information before first date on ga_copy
# get rid of any anchor dates with NA's
visits_clean <- visits_clean |>
  filter(elt_ts >= "2024-05-31",
         !is.na(anchor_date))

# change frequency to # of days that code correlates to
visits_clean <- visits_clean |>
  mutate(
  frequency = case_when(
    frequency == "01" ~ 7,
    frequency == "02" ~ 14,
    frequency == "04" ~ 28,
    TRUE ~ NA))

visits_clean <- visits_clean |>
  mutate(customer_id = trimws(as.character(customer_id)), # make it character type
         elt_ts = ymd_hms(elt_ts), 
         # replace any missing or null values with unknown
         distribution_mode = ifelse(is.na( distribution_mode) |  distribution_mode == ""|  distribution_mode == "null", "Unknown",  distribution_mode),
         sales_office_desc = ifelse(is.na(sales_office_desc) | sales_office_desc == ""| sales_office_desc == "null", "Unknown",sales_office_desc),
         sales_office = ifelse(is.na(sales_office) | sales_office == ""| sales_office == "null", "Unknown", sales_office),
         # date conversions
         snapshot_date = ymd(snapshot_date),
         anchor_date = ymd(anchor_date),
         snapshot_month = floor_date(snapshot_date, unit = "month"),
         anchor_month = floor_date(anchor_date, unit = "month"))
```

# Sales Clenaing

```{r}
# make column names lowercase, get rid of any spaces
sales_clean <- sales |>
  clean_names()

# conversion into correct column types
sales_clean <- sales_clean |>
  mutate(posting_date = mdy(posting_date),
         gross_profit_dead_net = as.numeric(gross_profit_dead_net))

# see how many negative profits and revenue there is
sales_clean |> summarise(
  neg_profit = sum(gross_profit_dead_net < 0),
  neg_nsi = sum(nsi_dead_net < 0)
)

# make column to show negatives
sales_clean <- sales_clean |>
  mutate(gross_profit_neg = if_else(gross_profit_dead_net < 0, "Negative", "Positive"),
         nsi_neg = if_else(nsi_dead_net < 0, "Negative", "Positive"))
```

# Other Cleaning

```{r}
# changing variables to correct types
customer_clean <- customer |>
  mutate(CUSTOMER_NUMBER = as.character(CUSTOMER_NUMBER))

material_clean <- material |>
  mutate(MATERIAL_ID = as.character(MATERIAL_ID))

hours_clean <- operating_hours |>
  mutate(CALLING_ANCHOR_DATE = mdy(CALLING_ANCHOR_DATE),
         CUSTOMER_NUMBER = as.character(CUSTOMER_NUMBER))
```

# Create Order Windows

```{r}
#function to safely generate the sequence of POSIXct dates
#creates a sequence of dates (the end times of the order windows) where start or end dates are missing
safe_seq_dates <- function(start_date, end_date, by_str) {
  if (is.na(start_date) || is.na(end_date) || start_date >= end_date) {
    return(list(as_datetime(character(0), tz="UTC")))
  }
  return(list(seq.POSIXt(from = start_date, to = end_date, by = by_str)))
}

#get start and end times
#clean cutoff times so we can join
cutoff_lookup <- cutoff_times |>
  clean_names() |>
  mutate(CUTOFF_TIME_OF_DAY = hms(cutofftime_c)) |>
  filter(sales_office != 0 & plant_id != 0) |>
  select(SALES_OFFICE = sales_office, SHIPPING_CONDITION_TIME = shipping_condition_time, 
         DISTRIBUTION_MODE = distribution_mode, CUTOFF_TIME_OF_DAY)

#join customer and cutoff times so we can see the policies
policy_periods <- visits_clean |>
  rename(CUSTOMER_NUMBER = customer_id) |>
  left_join(customer_clean |> select(CUSTOMER_NUMBER, SALES_OFFICE, DISTRIBUTION_MODE_DESCRIPTION, SHIPPING_CONDITIONS_DESCRIPTION), by = "CUSTOMER_NUMBER") |>
  left_join(cutoff_lookup, by = c("sales_office" = "SALES_OFFICE", "distribution_mode" = "DISTRIBUTION_MODE", "SHIPPING_CONDITIONS_DESCRIPTION" = "SHIPPING_CONDITION_TIME")) |>
    #make policy start time (Anchor Date + Cutoff Time)
  mutate(CUTOFF_TIME_OF_DAY = replace_na(CUTOFF_TIME_OF_DAY, hms("17:00:00")),# Default to 5 PM
         ANCHOR_DATETIME = as_datetime(anchor_date, tz="UTC") + hours(hour(CUTOFF_TIME_OF_DAY)) + 
         minutes(minute(CUTOFF_TIME_OF_DAY)) + seconds(second(CUTOFF_TIME_OF_DAY))) |>
  #get policy end time, ends when the next anchor date starts
  group_by(CUSTOMER_NUMBER) |>
  arrange(CUSTOMER_NUMBER, ANCHOR_DATETIME) |> 
  distinct(CUSTOMER_NUMBER, ANCHOR_DATETIME, .keep_all = TRUE) |> #get rid of duplicates at the same time
  mutate(POLICY_END_DATETIME = lead(ANCHOR_DATETIME), #start of next policy
         ORDER_WINDOW_START_POLICY = ANCHOR_DATETIME,
         frequency_days = frequency) |>
  ungroup() |>
  select(CUSTOMER_NUMBER, ORDER_WINDOW_START_POLICY, POLICY_END_DATETIME, frequency_days) |>
  #remove any that do not have a window or it is too short
  filter(!is.na(ORDER_WINDOW_START_POLICY), !is.na(frequency_days)) |>
  mutate(DURATION_CHECK = difftime(POLICY_END_DATETIME, ORDER_WINDOW_START_POLICY, units = "secs")) |>
  filter(is.na(POLICY_END_DATETIME) | DURATION_CHECK > 1) |> 
  select(-DURATION_CHECK)

#need to see all order windows for every row
order_window_master <- policy_periods |>
  rowwise() |> 
  mutate(max_ga_date = as_datetime(max(ga_clean$day, na.rm = TRUE) + days(max(frequency_days, na.rm=TRUE) * 2), tz="UTC"), 
         effective_order_end = coalesce(POLICY_END_DATETIME - seconds(1), max_ga_date),
         #expected end of order window
         expected_order_end_times = safe_seq_dates(start_date = ORDER_WINDOW_START_POLICY, 
                                                   end_date = effective_order_end, 
                                                   by_str = paste(frequency_days, "days"))) |>
  ungroup() |>
  unnest(cols = expected_order_end_times) |> #expand list of dates into new rows
  #actual window start date
  mutate(ORDER_WINDOW_END = expected_order_end_times, 
         ORDER_WINDOW_START = ORDER_WINDOW_END - days(frequency_days)) |>
  #unique valid windows
  select(CUSTOMER_NUMBER, ORDER_WINDOW_START, ORDER_WINDOW_END) |>
  distinct()

#get target variable
#identify windows with cart intent
cart_activity_windows <- ga_clean |>
  filter(event_name %in% c("add_to_cart", "ProductAddtoCart_PLP_Clicked", "ProductAddtoCart_PDP_Clicked")) |>
  mutate(EVENT_TIMESTAMP = ymd_hms(event_timestamp, tz="UTC")) |>
  select(CUSTOMER_ID = customer_id, EVENT_TIMESTAMP) |>
  #join cart events to the window they occurred in
  left_join(order_window_master |> rename(CUSTOMER_ID = CUSTOMER_NUMBER), 
            by = join_by(CUSTOMER_ID, 
                         closest(EVENT_TIMESTAMP >= ORDER_WINDOW_START), 
                         closest(EVENT_TIMESTAMP < ORDER_WINDOW_END))) |>
  filter(!is.na(ORDER_WINDOW_START)) |> 
  select(CUSTOMER_ID, ORDER_WINDOW_START, ORDER_WINDOW_END) |>
  distinct() |>
  mutate(HAD_CART_ACTIVITY = TRUE)

#identify windows with purchase
purchase_made_windows <- orders_clean |>
  filter(order_purchased == "Purchased") |>
  mutate(EVENT_TIMESTAMP = created_date_utc) |>
  select(CUSTOMER_ID = customer_id, EVENT_TIMESTAMP) |>
  #join purchases to the window they occurred in
  left_join(order_window_master |> rename(CUSTOMER_ID = CUSTOMER_NUMBER), 
            by = join_by(CUSTOMER_ID, 
                         closest(EVENT_TIMESTAMP >= ORDER_WINDOW_START),
                         closest(EVENT_TIMESTAMP < ORDER_WINDOW_END))) |>
  filter(!is.na(ORDER_WINDOW_START)) |>
  select(CUSTOMER_ID, ORDER_WINDOW_START, ORDER_WINDOW_END) |>
  distinct() |>
  mutate(MADE_PURCHASE = TRUE)

#create the target Variable
final_window_target <- order_window_master |>
  rename(CUSTOMER_ID = CUSTOMER_NUMBER) |>
  #merge the activity and purchase flags back onto the master list of windows
  left_join(cart_activity_windows, by = c("CUSTOMER_ID", "ORDER_WINDOW_START", "ORDER_WINDOW_END")) |>
  left_join(purchase_made_windows, by = c("CUSTOMER_ID", "ORDER_WINDOW_START", "ORDER_WINDOW_END")) |>
  #change NA to false
  mutate(HAD_CART_ACTIVITY = replace_na(HAD_CART_ACTIVITY, FALSE),
         MADE_PURCHASE = replace_na(MADE_PURCHASE, FALSE)) |>
  #target variable
  mutate(TARGET_ABANDONED = case_when(HAD_CART_ACTIVITY == TRUE & MADE_PURCHASE == FALSE ~ 1, TRUE ~ 0))

#put all together into one dataset
master_model_data <- ga_clean |>
    mutate(EVENT_TIMESTAMP = ymd_hms(event_timestamp, tz="UTC")) |>
    #join GA Events to their corresponding window
    left_join(order_window_master |> rename(CUSTOMER_ID = CUSTOMER_NUMBER),
              by = join_by(customer_id == CUSTOMER_ID,
                           closest(EVENT_TIMESTAMP >= ORDER_WINDOW_START),
                           closest(EVENT_TIMESTAMP < ORDER_WINDOW_END))) |>
    #join the target status to the events
    left_join(final_window_target |> select(CUSTOMER_ID, ORDER_WINDOW_START, ORDER_WINDOW_END, TARGET_ABANDONED),
              by = c("customer_id" = "CUSTOMER_ID", "ORDER_WINDOW_START", "ORDER_WINDOW_END")) |>
    #select columns for modeling
    select(CUSTOMER_ID = customer_id, EVENT_TIMESTAMP, event_name, event_grouped, device_category, ORDER_WINDOW_START, ORDER_WINDOW_END, TARGET_ABANDONED)
```

# Remove NAs

```{r}
#look into how many customers there are total and is any have NAs
length(unique(master_model_data$CUSTOMER_ID))
length(unique(master_model_data$CUSTOMER_ID[rowSums(is.na(master_model_data)) > 0]))

#remove customers that have NAs present
na_customer_ids_to_remove <- master_model_data %>%
  filter(rowSums(is.na(master_model_data)) > 0) %>%
  distinct(CUSTOMER_ID)

master_model_data_clean <- master_model_data %>%
  anti_join(na_customer_ids_to_remove, by = "CUSTOMER_ID")

#confirm that it worked
(unique(master_model_data_clean$CUSTOMER_ID[rowSums(is.na(master_model_data_clean)) > 0]))
length(unique(master_model_data_clean$CUSTOMER_ID))

colSums(is.na(master_model_data_clean))

skim(master_model_data_clean)
```

# Sample data

```{r}
#sample data for quicker run times
set.seed(123)

#going to sample 50% of unique customers to start to see how it works
sample_ids <- master_model_data_clean %>%
  distinct(CUSTOMER_ID)  %>%
  slice_sample(prop = 0.5)  %>%
  pull(CUSTOMER_ID)

master_model_data_clean_sample <- master_model_data_clean  %>%
  filter(CUSTOMER_ID %in% sample_ids)

#adding in a purchase indicating variable
master_model_data_clean_sample <- master_model_data_clean_sample %>%
  mutate(is_purchase_event = ifelse(event_grouped == "Purchase", 1, 0))

skim(master_model_data_clean_sample)
```

# Majority Class

```{r}
#majority class classifier
mean(master_model_data_clean_sample$TARGET_ABANDONED)

table(master_model_data_clean_sample$TARGET_ABANDONED)
```

# Cross Validation

```{r}
# we need to split the train data so we have a validation set for cross-validation. We will split 70/30, and by customer
set.seed(123)

all_customer_ids <- master_model_data_clean_sample %>%
  distinct(CUSTOMER_ID) %>%
  pull(CUSTOMER_ID) 

index <- sample(x = all_customer_ids, size = floor(length(all_customer_ids) * 0.70), replace = FALSE)

# Subset train using index to create a 70% train_fold
train_fold <- master_model_data_clean_sample %>% 
  filter(CUSTOMER_ID %in% index)

# Subset the remaining rows not included in index to create a 30% validation fold
validation_fold <- master_model_data_clean_sample %>% 
  filter(!(CUSTOMER_ID %in% index))
```

# Fix Class Imbalance

```{r}
#large imbalance so going to down sample because still many observations
table(train_fold$TARGET_ABANDONED)

#have to make factor 
train_fold_factor <- train_fold %>%
  mutate(TARGET_ABANDONED = factor(TARGET_ABANDONED))

train_data_balanced <- caret::downSample(x = train_fold_factor %>% select(-TARGET_ABANDONED), y = train_fold_factor$TARGET_ABANDONED)

train_data_balanced <- train_data_balanced %>% rename(TARGET_ABANDONED = Class)

table(train_data_balanced$TARGET_ABANDONED)
```

# Logistic Regression

```{r}
#basic logistic regression with event name
basic_regression_name <- glm(TARGET_ABANDONED ~ event_name + device_category, data = train_data_balanced, family = binomial)
summary(basic_regression_name)
```

```{r}
#AUC, precision, recall
# Predicted probabilities on training data
predicted_probs <- predict(basic_regression_name, type = "response")

# AUC
library(pROC)
roc_obj <- roc(train_data_balanced$TARGET_ABANDONED, predicted_probs)
auc(roc_obj)
plot(roc_obj, col = "blue")  # optional ROC curve

# Convert to class predictions (threshold = 0.5)
predicted_class <- ifelse(predicted_probs >= 0.5, 1, 0)

# Confusion matrix
confusionMatrix(factor(predicted_class),
                factor(train_data_balanced$TARGET_ABANDONED),
                positive = "1")
```

## Logistic Regression with grouped events

```{r}
#basic logistic regression with event grouped (faster)
basic_regression_group <- glm(TARGET_ABANDONED ~ event_grouped + device_category, data = train_data_balanced, family = binomial)
summary(basic_regression_group)
```

```{r}
#AUC, precision, recall
# Predicted probabilities on training data
predicted_probs <- predict(basic_regression_group, type = "response")

# AUC
library(pROC)
roc_obj <- roc(train_data_balanced$TARGET_ABANDONED, predicted_probs)
auc(roc_obj)
plot(roc_obj, col = "blue")  # optional ROC curve

# Convert to class predictions (threshold = 0.5)
predicted_class <- ifelse(predicted_probs >= 0.5, 1, 0)

# Confusion matrix
confusionMatrix(factor(predicted_class),
                factor(train_data_balanced$TARGET_ABANDONED),
                positive = "1")
```

## Logistic Regression with interaction

```{r}
#added interaction
interaction_regression <- glm(TARGET_ABANDONED ~ event_grouped + device_category * is_purchase_event, data = train_data_balanced, family = binomial)
summary(interaction_regression)

```

```{r}
#AUC, precision, recall
# Predicted probabilities on training data
predicted_probs <- predict(interaction_regression, type = "response")

# AUC
library(pROC)
roc_obj <- roc(train_data_balanced$TARGET_ABANDONED, predicted_probs)
auc(roc_obj)
plot(roc_obj, col = "blue")  # optional ROC curve

# Convert to class predictions (threshold = 0.5)
predicted_class <- ifelse(predicted_probs >= 0.5, 1, 0)

# Confusion matrix
confusionMatrix(factor(predicted_class),
                factor(train_data_balanced$TARGET_ABANDONED),
                positive = "1")
```

# Random Forest

```{r}
#Random forest model (lasts long)
train_control <- trainControl(method = "cv", number = 5, classProbs = TRUE, summaryFunction = twoClassSummary)

train_data_balanced_factor <- train_data_balanced %>% 
  mutate(TARGET_ABANDONED = factor(TARGET_ABANDONED, levels = c("0", "1"), labels = c("No_Abandon", "Abandon")))

# fit single model with RF as the base learner
rf_mod <- train(TARGET_ABANDONED ~ event_grouped + device_category,
                data = train_data_balanced_factor,
                method = "ranger",
                metric = "ROC",
                trControl = train_control,
                num.trees = 250)

print(rf_mod$results)
```

```{r}
#AUC, precision, recall
# Predicted probabilities on training data
predicted_probs <- predict(rf_mod, newdata = train_data_balanced_factor, type = "prob")[, "Abandon"]

# AUC
library(pROC)
roc_obj <- roc(train_data_balanced$TARGET_ABANDONED, predicted_probs)
auc(roc_obj)
plot(roc_obj, col = "blue")  # optional ROC curve

# Convert to class predictions (threshold = 0.5)
predicted_class <- ifelse(predicted_probs >= 0.5, 1, 0)

# Confusion matrix
confusionMatrix(factor(predicted_class),
                factor(train_data_balanced$TARGET_ABANDONED),
                positive = "1")
```

# XGBoost

```{r}
#xgboost (took 45 mins)
library(xgboost)
predictors_train <- train_data_balanced %>% 
  select(event_name, device_category, is_purchase_event)

dummy_recipe <- dummyVars(~ ., data = predictors_train)

train_matrix <- predict(dummy_recipe, newdata = predictors_train)

train_target_numeric <- as.numeric(as.character(train_data_balanced$TARGET_ABANDONED))

xgb_train_data <- xgb.DMatrix(data = train_matrix, label = train_target_numeric)

xgb_tune_grid <- expand.grid(
  nrounds = c(50, 150, 300),          # <-- Tests 50, 150, and 300 trees
  max_depth = c(2, 4),               # Depth of each tree
  eta = c(0.1, 0.3),                 # Learning rate (how fast to learn)
  gamma = 0,                         # Min loss reduction to make a split
  colsample_bytree = 0.8,
  min_child_weight = 1,
  subsample = 0.8
)

xgb_mod <- train(x = train_matrix, 
                 y = train_data_balanced_factor$TARGET_ABANDONED,
                 method = "xgbTree",
                 metric = "ROC",
                 trControl = train_control,
                 tuneGrid = xgb_tune_grid)
```

```{r}
#AUC, precision, recall
# Predicted probabilities on training data
predicted_probs <- predict(xgb_mod, newdata = train_matrix, type = "prob")[, "Abandon"]

# AUC
roc_obj <- roc(train_data_balanced_factor$TARGET_ABANDONED, predicted_probs)
auc(roc_obj)
plot(roc_obj, col = "blue")  # optional ROC curve

# Convert to class predictions (threshold = 0.5)
predicted_class <- ifelse(predicted_probs >= 0.5, 1, 0)

# Confusion matrix
confusionMatrix(factor(predicted_class),
                factor(train_data_balanced$TARGET_ABANDONED),
                positive = "1")
```

# Lasso

```{r}
#lasso
library(glmnet)
lasso_model <- train(
  x = train_matrix, 
  y = train_data_balanced_factor$TARGET_ABANDONED,
  method = "glmnet",
  metric = "ROC",
  trControl = train_control,
  # Alpha = 1 for LASSO, Alpha = 0 for Ridge, use grid for tuning
  tuneGrid = expand.grid(alpha = 1, lambda = 10^seq(10, -2, length=100)) 
)
```

```{r}
#AUC, precision, recall
# Predicted probabilities on training data
predicted_probs <- predict(lasso_model, newdata = train_matrix, type = "prob")[, "Abandon"]

# AUC
library(pROC)
roc_obj <- roc(train_data_balanced_factor$TARGET_ABANDONED, predicted_probs)
auc(roc_obj)
plot(roc_obj, col = "blue")  # optional ROC curve

# Convert to class predictions (threshold = 0.5)
predicted_class <- ifelse(predicted_probs >= 0.5, 1, 0)

# Confusion matrix
confusionMatrix(factor(predicted_class),
                factor(train_data_balanced$TARGET_ABANDONED),
                positive = "1")
```

